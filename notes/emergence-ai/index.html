<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Emergence in AI Models: Does Water Really Boil? | Bits & Qubits</title>
<meta name=keywords content><meta name=description content="We need to decide what observables and metrics are worth paying attention to."><meta name=author content><link rel=canonical href=https://pradeepniroula.com/notes/emergence-ai/><link crossorigin=anonymous href=/assets/css/stylesheet.81560bb2cda567b7f3f27780a8ff38e04f142b7daaa04538e4a6f1ec6d5f4cd2.css integrity="sha256-gVYLss2lZ7fz8neAqP844E8UK32qoEU45Kbx7G1fTNI=" rel="preload stylesheet" as=style><link rel=icon href=https://pradeepniroula.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pradeepniroula.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pradeepniroula.com/favicon-32x32.png><link rel=apple-touch-icon href=https://pradeepniroula.com/apple-touch-icon.png><link rel=mask-icon href=https://pradeepniroula.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pradeepniroula.com/notes/emergence-ai/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-877BXHD6V6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-877BXHD6V6")}</script><meta property="og:url" content="https://pradeepniroula.com/notes/emergence-ai/"><meta property="og:site_name" content="Bits & Qubits"><meta property="og:title" content="Emergence in AI Models: Does Water Really Boil?"><meta property="og:description" content="We need to decide what observables and metrics are worth paying attention to."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2024-01-09T00:00:00+00:00"><meta property="article:modified_time" content="2024-01-09T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Emergence in AI Models: Does Water Really Boil?"><meta name=twitter:description content="We need to decide what observables and metrics are worth paying attention to."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Notes","item":"https://pradeepniroula.com/notes/"},{"@type":"ListItem","position":2,"name":"Emergence in AI Models: Does Water Really Boil?","item":"https://pradeepniroula.com/notes/emergence-ai/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Emergence in AI Models: Does Water Really Boil?","name":"Emergence in AI Models: Does Water Really Boil?","description":"We need to decide what observables and metrics are worth paying attention to.","keywords":[],"articleBody":"Emergence is the new hot topic in AI Research. When I first heard of it in a Sanjeev Arora talk, the word felt heavy, profound, mysterious. I thought of genesis; it evoked in me visions of consciousness emerging out of ether. It took me back to the “More is Different” essay by PW Anderson. In short, it stirred…feelings.\nEmergence is an observation that, as you scale up an AI model, for instance in the number of parameters, the model suddenly acquires an ability to solve new problems; an emergent ability is one that is not present in smaller models but exists in larger models. Many language models have been shown to demonstrate emergence across many tasks (adding numbers, unscrambling words etc.), even raising existential concerns that, perhaps, AI models will one day develop some ability we don’t quite fathom yet. Two key features of the emergence, as it has been noted, are unpredictability and suddenness. As you make the models bigger, there is some kind of transition between the model performing poorly on task X and it performing very well on the same task. Unpredictability means that for any given task (say writing Python code), it is not possible to anticipate at what parameter size such a sudden jump in performance appears.\nA provocative paper, which recently was awarded the best-paper award at NeurIPS 2023, has brought new attention to emergence. The paper argues that the emergent behavior researchers have hitherto observed is simply a delusion due to researchers looking at the wrong and complex metrics, and that if you only looked at simple (or as the paper argues: correct) observables, this mirage would fade away.\nThe author’s argument is simple. While the central measure of a language model’s performance is the ‘error per token’ metric (which measures how well a model can generate the next symbol in the sequence), the tasks for which we have seen emergence tend to be extremely complex, non-linear functions of this fundamental metric. Instead, if you look at functions linear in ‘error per token’, such transitions go away. For example, suppose I want the AI model to predict an answer to the Wordle game, which requires it to produce a correct sequence of five letters. If each token has a success probability of p, the accuracy at getting the exact right answer scales like $p^5$. It is also not surprising that as p increases gradually, the ability to get exact answer emerges suddenly. But, if you define your accuracy as the ‘edit distance from the perfect word’, then it scales linearly in p, and you do not see any kind of emergence here.\nAt the crux of this debate is the fundamental question: what metrics and observables are worth paying attention to?\nIt seems to me that the most interesting problems people care about (making radiological diagnosis, weather forecasts, adding numbers, generating videos from text etc.) are non-linear functions of the base error-per-token parameter. The world where you only cared about linear functions would not only be boring, but likely of very limited use. As Jason Wei notes, arithmetic is an example of problem for which exactness matters. If you ask an AI model to add 250 to 130, you would demand a correct answer of 380. You could argue that 379 is closer to 380 than, say, -2.22. But, if you simply looked at “edit distance”, is it reasonable to say that 381, 038, and -380 are all equally good?\nIf anything, the nonlinearities are what makes things interesting. As I heat water, its internal energy increases continuously. At a particular temperature, the water inevitably boils, with a sudden change in density (which happens to be a non-linear function of free energy). If you only looked at the internal energy, you wouldn’t even notice the water boiling. And, the “observable” phases of water and the fact that liquids tend to boil (with steam being the result of this emergence) are arguably more interesting than invisible attributes like internal energy.\nThis is by no means a slight on the work by Schaeffer et al. These arguments about metrics are symptomatic of a field undergoing rapid progress, and this work provides a fresh counterpoint to feverish conversations about emergence. Also, the second thrust of their work, where they show that, even for non-linear metrics, emergence fades away once you take enough data to measure accuracy is also super interesting, and I wish I understood it better. At any rate, as grandiose the term “emergence” sounds, all these works seem to be pointing at something utterly banal and boring: “nice linear things happen if you look at linear functions, and strange non-linear things happen if you look at non-linear functions.”\n- January 2023\n","wordCount":"787","inLanguage":"en","datePublished":"2024-01-09T00:00:00Z","dateModified":"2024-01-09T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://pradeepniroula.com/notes/emergence-ai/"},"publisher":{"@type":"Organization","name":"Bits \u0026 Qubits","logo":{"@type":"ImageObject","url":"https://pradeepniroula.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pradeepniroula.com/ accesskey=h title="Bits & Qubits (Alt + H)">Bits & Qubits</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href="https://scholar.google.com/citations?user=sozxaMYAAAAJ&amp;hl=en" title=Research><span>Research</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://pradeepniroula.com/reviews/ title=Briefs><span>Briefs</span></a></li><li><a href=https://pradeepniroula.com/notes/ title=Notes><span>Notes</span></a></li><li><a href=https://pradeepniroula.com/writings/ title=Writings><span>Writings</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Emergence in AI Models: Does Water Really Boil?</h1><div class=post-meta><span title='2024-01-09 00:00:00 +0000 UTC'>January 9, 2024</span></div></header><div class=post-content><p>Emergence is the new hot topic in AI Research. When I first heard of it in a Sanjeev Arora <a href="https://www.youtube.com/watch?v=0D23NeBjCeQ">talk</a>, the word felt heavy, profound, mysterious. I thought of genesis; it evoked in me visions of consciousness emerging out of ether. It took me back to the <a href=https://www.science.org/doi/10.1126/science.177.4047.393>“More is Different”</a> essay by PW Anderson. In short, it stirred…feelings.</p><p>Emergence is an observation that, as you scale up an AI model, for instance in the number of parameters, the model suddenly acquires an ability to solve new problems; an emergent ability is one that is not present in smaller models but exists in larger models. Many language models have been <a href=https://arxiv.org/abs/2206.07682>shown</a> to demonstrate emergence across many tasks (adding numbers, unscrambling words etc.), even <a href=https://www.lesswrong.com/posts/vwLxd6hhFvPbvKmBH/yudkowsky-and-christiano-discuss-takeoff-speeds#_Yudkowsky__17_22_>raising</a> existential concerns that, perhaps, AI models will one day develop some ability we don’t quite fathom yet. Two key features of the emergence, as it has been noted, are unpredictability and suddenness. As you make the models bigger, there is some kind of transition between the model performing poorly on task X and it performing very well on the same task. Unpredictability means that for any given task (say writing Python code), it is not possible to anticipate at what parameter size such a sudden jump in performance appears.</p><p><img alt=image loading=lazy src=/notes/emergence.png></p><p>A <a href=https://arxiv.org/abs/2304.15004>provocative paper</a>, which recently was awarded the best-paper award at NeurIPS 2023, has brought new attention to emergence. The paper argues that the emergent behavior researchers have hitherto observed is simply a delusion due to researchers looking at the wrong and complex metrics, and that if you only looked at simple (or as the paper argues: correct) observables, this mirage would fade away.</p><p>The author’s argument is simple. While the central measure of a language model’s performance is the ‘error per token’ metric (which measures how well a model can generate the next symbol in the sequence), the tasks for which we have seen emergence tend to be extremely complex, non-linear functions of this fundamental metric. Instead, if you look at functions linear in ‘error per token’, such transitions go away. For example, suppose I want the AI model to predict an answer to the Wordle game, which requires it to produce a correct sequence of five letters. If each token has a success probability of p, the accuracy at getting the exact right answer scales like $p^5$. It is also not surprising that as p increases gradually, the ability to get exact answer emerges suddenly. But, if you define your accuracy as the ‘edit distance from the perfect word’, then it scales linearly in p, and you do not see any kind of emergence here.</p><p>At the crux of this debate is the fundamental question: what metrics and observables are worth paying attention to?</p><p>It seems to me that the most interesting problems people care about (making radiological diagnosis, weather forecasts, adding numbers, generating videos from text etc.) are non-linear functions of the base error-per-token parameter. The world where you only cared about linear functions would not only be boring, but likely of very limited use. As Jason Wei <a href=https://www.jasonwei.net/blog/common-arguments-regarding-emergent-abilities>notes</a>, arithmetic is an example of problem for which exactness matters. If you ask an AI model to add 250 to 130, you would demand a correct answer of 380. You could argue that 379 is closer to 380 than, say, -2.22. But, if you simply looked at “edit distance”, is it reasonable to say that 381, 038, and -380 are all equally good?</p><p>If anything, the nonlinearities are what makes things interesting. As I heat water, its internal energy increases continuously. At a particular temperature, the water inevitably boils, with a sudden change in density (which happens to be a non-linear function of free energy). If you only looked at the internal energy, you wouldn’t even notice the water boiling. And, the “observable” phases of water and the fact that liquids tend to boil (with steam being the result of this emergence) are arguably more interesting than invisible attributes like internal energy.</p><p>This is by no means a slight on the work by Schaeffer et al. These arguments about metrics are symptomatic of a field undergoing rapid progress, and this work provides a fresh counterpoint to feverish conversations about emergence. Also, the second thrust of their work, where they show that, even for non-linear metrics, emergence fades away once you take enough data to measure accuracy is also super interesting, and I wish I understood it better. At any rate, as grandiose the term “emergence” sounds, all these works seem to be pointing at something utterly banal and boring: “nice linear things happen if you look at linear functions, and strange non-linear things happen if you look at non-linear functions.”</p><p>- January 2023</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pradeepniroula.com/>Bits & Qubits</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>