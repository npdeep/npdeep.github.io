<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Making the World a Better Place, with M&amp;Ms | Bits & Qubits</title>
<meta name=keywords content><meta name=description content="How I am using reinforcement learning and M&amp;Ms to improve the world around me."><meta name=author content><link rel=canonical href=https://pradeepniroula.com/notes/reinforcement-learning-candies/><link crossorigin=anonymous href=/assets/css/stylesheet.1269d1fd98ef7ba64ca2571bec809ff961002ef2a51986ed3cb5e4ae8c37fe0b.css integrity="sha256-EmnR/Zjve6ZMolcb7ICf+WEALvKlGYbtPLXkrow3/gs=" rel="preload stylesheet" as=style><link rel=icon href=https://pradeepniroula.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pradeepniroula.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pradeepniroula.com/favicon-32x32.png><link rel=apple-touch-icon href=https://pradeepniroula.com/apple-touch-icon.png><link rel=mask-icon href=https://pradeepniroula.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pradeepniroula.com/notes/reinforcement-learning-candies/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-877BXHD6V6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-877BXHD6V6")}</script><meta property="og:url" content="https://pradeepniroula.com/notes/reinforcement-learning-candies/"><meta property="og:site_name" content="Bits & Qubits"><meta property="og:title" content="Making the World a Better Place, with M&Ms"><meta property="og:description" content="How I am using reinforcement learning and M&amp;Ms to improve the world around me."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2025-03-02T00:00:00+00:00"><meta property="article:modified_time" content="2025-03-02T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Making the World a Better Place, with M&amp;Ms"><meta name=twitter:description content="How I am using reinforcement learning and M&amp;Ms to improve the world around me."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Notes","item":"https://pradeepniroula.com/notes/"},{"@type":"ListItem","position":2,"name":"Making the World a Better Place, with M\u0026Ms","item":"https://pradeepniroula.com/notes/reinforcement-learning-candies/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Making the World a Better Place, with M\u0026Ms","name":"Making the World a Better Place, with M\u0026Ms","description":"How I am using reinforcement learning and M\u0026amp;Ms to improve the world around me.","keywords":[],"articleBody":"These days, I always carry with me a bag of M\u0026Ms. This is what it looks like:\nI have been using M\u0026Ms to promote good behavior around me. The idea is that if I start rewarding myself as well as people/agents around me based on their behavior, following the theory of reinforcement learning, it will slowly nudge myself as well as others towards doing good things.\nFor example, If I do something good, like go to the gym or wake up early or actually read a paper or finish some item in my TODO list, I give myself a single M\u0026M. Given my sweet-tooth, this conditions me towards pursuing good behavior. I started following this protocol February 1st. Just look at my progress through the month of February in this diagram. Each candy dispensed is a task successfully completed.\nLikewise, if someone holds a door open for me, or tells me a funny joke, or makes an astute observation, I immediately reward them with an M\u0026M. If it is not possible to give them a candy, for example a cyclist passing by, I yell out my appreciation: “Thank you! I am proud of you! Everyone should be proud of you!”\nSimilarly, I dispense negative rewards whenever someone does something bad or stupid. If someone, for example blocks my way up an escalator or starts yapping about LLMs or how excited they are about the new season of White Lotus, I tell them something mean: “That color does not look good on you” or “Our ancestors would have never invented language if they knew it would lead to you uttering this nonsense.” The hope is that, over time, this minimizes suboptimal behavior around me.\nFinally, I encourage you all, my readers, to adopt a similar system in your lives. The biggest issue with the world right now is that we don’t have such immediate feedback loops everywhere. We would reach convergence to good behavior much quicker if everybody participated.\n[NOTE: A lot of you are emailing me about someone named Pavlov. Sorry, I have never met him.]\n","wordCount":"346","inLanguage":"en","datePublished":"2025-03-02T00:00:00Z","dateModified":"2025-03-02T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://pradeepniroula.com/notes/reinforcement-learning-candies/"},"publisher":{"@type":"Organization","name":"Bits \u0026 Qubits","logo":{"@type":"ImageObject","url":"https://pradeepniroula.com/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://pradeepniroula.com/ accesskey=h title="Bits & Qubits (Alt + H)">Bits & Qubits</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bleedingedges.substack.com/ title="BLEEDING EDGES (NEWSLETTER)"><span>BLEEDING EDGES (NEWSLETTER)</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href="https://scholar.google.com/citations?user=sozxaMYAAAAJ&amp;hl=en" title=Research><span>Research</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://pradeepniroula.com/reviews/ title=Briefs><span>Briefs</span></a></li><li><a href=https://pradeepniroula.com/notes/ title=Notes><span>Notes</span></a></li><li><a href=https://pradeepniroula.com/writings/ title=Writings><span>Writings</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Making the World a Better Place, with M&amp;Ms</h1><div class=post-meta><span title='2025-03-02 00:00:00 +0000 UTC'>March 2, 2025</span></div></header><div class=post-content><p>These days, I always carry with me a bag of M&amp;Ms. This is what it looks like:</p><p><img alt=image loading=lazy src=/notes/m&m.png></p><p>I have been using M&amp;Ms to promote good behavior around me. The idea is that if I start rewarding myself as well as people/agents around me based on their behavior, following the theory of reinforcement learning, it will slowly nudge myself as well as others towards doing good things.</p><p>For example, If I do something good, like go to the gym or wake up early or actually read a paper or finish some item in my TODO list, I give myself a single M&amp;M. Given my sweet-tooth, this conditions me towards pursuing good behavior. I started following this protocol February 1st. Just look at my progress through the month of February in this diagram. Each candy dispensed is a task successfully completed.</p><p><img alt=image loading=lazy src=/notes/rl-progress.png></p><p>Likewise, if someone holds a door open for me, or tells me a funny joke, or makes an astute observation, I immediately reward them with an M&amp;M. If it is not possible to give them a candy, for example a cyclist passing by, I yell out my appreciation: &ldquo;Thank you! I am proud of you! Everyone should be proud of you!&rdquo;</p><p>Similarly, I dispense negative rewards whenever someone does something bad or stupid. If someone, for example blocks my way up an escalator or starts yapping about LLMs or how excited they are about the new season of White Lotus, I tell them something mean: &ldquo;That color does not look good on you&rdquo; or &ldquo;Our ancestors would have never invented language if they knew it would lead to you uttering this nonsense.&rdquo; The hope is that, over time, this minimizes suboptimal behavior around me.</p><p>Finally, I encourage you all, my readers, to adopt a similar system in your lives. The biggest issue with the world right now is that we don&rsquo;t have such immediate feedback loops everywhere. We would reach convergence to good behavior much quicker if everybody participated.</p><p>[NOTE: A lot of you are emailing me about someone named Pavlov. Sorry, I have never met him.]</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://pradeepniroula.com/>Bits & Qubits</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>