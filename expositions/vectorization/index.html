<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Understanding gcc Vectorization | Bits & Qubits</title>
<meta name=keywords content><meta name=description content="What happens under the hood when your compiler auto-vectorizes?"><meta name=author content><link rel=canonical href=https://pradeepniroula.com/expositions/vectorization/><link crossorigin=anonymous href=/assets/css/stylesheet.4c86e0df998370c7284999bb91f6d1caf42fc955fd6c92a6a4ed6686c335e46e.css integrity="sha256-TIbg35mDcMcoSZm7kfbRyvQvyVX9bJKmpO1mhsM15G4=" rel="preload stylesheet" as=style><link rel=icon href=https://pradeepniroula.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pradeepniroula.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pradeepniroula.com/favicon-32x32.png><link rel=apple-touch-icon href=https://pradeepniroula.com/apple-touch-icon.png><link rel=mask-icon href=https://pradeepniroula.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pradeepniroula.com/expositions/vectorization/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-877BXHD6V6"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-877BXHD6V6")}</script><meta property="og:title" content="Understanding gcc Vectorization"><meta property="og:description" content="What happens under the hood when your compiler auto-vectorizes?"><meta property="og:type" content="article"><meta property="og:url" content="https://pradeepniroula.com/expositions/vectorization/"><meta property="article:section" content="expositions"><meta property="article:published_time" content="2021-11-07T00:00:00+00:00"><meta property="article:modified_time" content="2021-11-07T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Understanding gcc Vectorization"><meta name=twitter:description content="What happens under the hood when your compiler auto-vectorizes?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Technical Notes and Expositions","item":"https://pradeepniroula.com/expositions/"},{"@type":"ListItem","position":2,"name":"Understanding gcc Vectorization","item":"https://pradeepniroula.com/expositions/vectorization/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Understanding gcc Vectorization","name":"Understanding gcc Vectorization","description":"What happens under the hood when your compiler auto-vectorizes?","keywords":[],"articleBody":" It took me a very long time to understand what people mean when they say vectorization (well at least for CPUs).\nConsider a simple function to multiply an array by a scalar\nvoid vec_mult_scalar(int a[], int c) { int i; for(i=0; i\u003c4096; i++){ a[i] *= c; } } A couple of things to note. First, I have assumed the array is of length 4096. This makes digging into the assembly instruction slightly easier. Second, the size of the array has to be kind of large. Vectorization doesn’t come cheap — for small arrays, the program might actually run faster without any vectorization. The Naive Way of Multiplying an Array Let’s compile the code above without optimization (by using the compiler flag -O0) and read the assembly output. gcc -O0 vec_mult_scalar.c -S \u0026\u0026 cat vec_mult_scalar.S The assembly output looks like the following ## %bb.0: pushq\t%rbp .cfi_def_cfa_offset 16 .cfi_offset %rbp, -16 movq\t%rsp, %rbp .cfi_def_cfa_register %rbp xorl\t%eax, %eax .p2align\t4, 0x90 LBB0_1: ## =\u003eThis Inner Loop Header: Depth=1 movl\t(%rdi,%rax,4), %ecx imull\t%esi, %ecx movl\t%ecx, (%rdi,%rax,4) incq\t%rax cmpq\t$4096, %rax ## imm = 0x1000 jne\tLBB0_1 ## %bb.2: popq\t%rbp retq .cfi_endproc ## -- End function Let’s try to parse the assembly instruction line by line. The main program only begins from the label LBB0_1. The stuff before is irrelevant to this dicussion. Before we dig into the assembly code above, a couple of things to remember:\nThe first thing to know is that, when a function is called, the memory addresses of the arguments passed are stored in registers. The first argument gets stored in regsiter %rdi, the second in %rsi and so on. To learn more about the exact order, I would recommend this page. The register %esi is the lower half of %rsi. While %rsi is a 64-bit register, %esi uses the lower 32-bits. More details here on how the r-registers and e-registers are related. The command movl A, B moves stuff from register A to register B. The suffix l simply means that the register has the size long. The other tricky thing is the notation (A, B, C). It usually means: take the stuff in B, multiply that by stuff in C and add it to A. This is usually helpful in fetching array indices. For example, if the first element of an integer array $X$ is stored in the register %rdx, (%rdx, 1, 4) would get the memory address %rdx + 4 which would be the array element X[i], since integer arrays are stored in strides of 4 bytes. Similarly, D(A, B, C) means add D to the result of (A, B, C). Now we are ready to understand the assembly output.\nmovl\t(%rdi,%rax,4), %ecx simply moves %rdi + 4%rax to %ecx. %rax presumably is holding the loop counter i. You need to multiply by 4 because each memory address stores a byte and an integer is 4 bytes long. This is similar to fetching the array item a[i]. imull\t%esi, %ecx multiplies the stuff we just stored in %ecx with whatever is in %esi. The %esi register is just the lower half of %rsi, so it is storing the 32-bit integer we passed as a scalar parameter. After the multiplication, we return the multiplied stuff at %ecx back to the array memory movl\t%ecx, (%rdi,%rax,4). incq %rax just increase the counter variable by 1. cmpq\t$4096, %rax compares the counter with 4096. If the counter is less than 4096, the line jne\tLBB0_1 returns it back to the top of the loop. The loop is very dumb. It moves an element of array to a temporary calculator, multiplies the data in calculator, and returns the new data back to the memory where it came from. This process is repeated for each element in the array one at a time.\nVectorized Compilation Now let’s turn on vectorization and see what the assembly code looks like in this case. gcc -O3 vectorization.c -S \u0026\u0026 cat vectorization.s gives the following assembly code.\n## %bb.0: pushq\t%rbp .cfi_def_cfa_offset 16 .cfi_offset %rbp, -16 movq\t%rsp, %rbp .cfi_def_cfa_register %rbp movd\t%esi, %xmm0 pshufd\t$0, %xmm0, %xmm0 xorl\t%eax, %eax .p2align\t4, 0x90 LBB0_1: ## =\u003eThis Inner Loop Header: Depth=1 movdqu\t(%rdi,%rax,4), %xmm1 movdqu\t16(%rdi,%rax,4), %xmm2 movdqu\t32(%rdi,%rax,4), %xmm3 movdqu\t48(%rdi,%rax,4), %xmm4 pmulld\t%xmm0, %xmm1 pmulld\t%xmm0, %xmm2 movdqu\t%xmm1, (%rdi,%rax,4) movdqu\t%xmm2, 16(%rdi,%rax,4) pmulld\t%xmm0, %xmm3 pmulld\t%xmm0, %xmm4 movdqu\t%xmm3, 32(%rdi,%rax,4) movdqu\t%xmm4, 48(%rdi,%rax,4) addq\t$16, %rax cmpq\t$4096, %rax ## imm = 0x1000 jne\tLBB0_1 ## %bb.2: popq\t%rbp retq This certainly looks a bit more involved than before. The most important change to note is the presence of registers like %xmm0 and new commands like movdqu or pmulld.\nThe XMM registers are 128 bit registers. They can hold four 32-bit integers. And it can apply operations parallely across the entire register. What this means for us is that if we can pack the XMM register with four integers, we can multiply all of them at once. I borrowed the following picture from Intel’s Tutorial on Vectorization\nLet’s dig into the assembly code\nJust before the main LBB0_1 section begins, we see an instruction movd %esi, %xmm0. It just moves the scalar parameter c to the %xmm0 register. A few weird things here. The scalar is really a 32-bit integer. %xmm0 is a 128-bit register. And movd is treating the data being moved as a double (64 bit). For now, we can sweep the subtleties under the rug. At this point the register %xmm0 looks like the following 32 32 32 32 bits ---------------------------------------------------- | | | c ---------------------------------------------------- The command that follows immediately pshufd\t$0, %xmm0, %xmm0 is kind of complicated. This technical reference is also kind of opaque. All we need to know is that after this operation, the %xmm0 register looks like the following 32 32 32 32 bits ---------------------------------------------------- c | c | c | c ---------------------------------------------------- Entering the loop, the sequence of mov statements movdqu (%rdi, %rax,4), %xmm1; movdqu 16(%rdi,%rax,4), %xmm4; ...movdqu 48(%rdi,%rax,4), %xmm4 moves blocks of four integers (128 bits) from the array to the XMM register. movdqu just means move double quadwords (just another way of saying 128 bits). The block beginning from (%rdi, %rax,4) gets stored in %xmm1. Since %xmm1 has 128 bits, this should fit four integers. The block beginning from 16(%rdi, %rax,4) or rather (%rdi, %rax,4) + 16 goes to %xmm1. The 16 (with is just the length, in bytes, of four integers) is important because the data between (%rdi, %rax,4) + 0 and (%rdi, %rax,4) + 15 is stored in %xmm1 already. The operation pmulld %xmm0, %xmm1 just multiplies the block of four integers packed in %xmm1 with the scalar value packed in the register %xmm0. After the multiplication, the multiplied integers packed in the XMM registers are dragged back to the array memory location. For some reason, the compiler uses four XMM registers. It first multiplies two XMM registers in a row, moves the data, and then multiplies the remaining two registers. I do not fully understand why it doesn’t multiply all four in a row. Finally, once all numbers are multiplied, the loop exits. Takeaways Vectorization is achieved by using these humongous XMM registers that can do parallel operations. The compiler can optimize most loops – as long as the loops are simple enough. For auto-vectorization to work, the loop counters must be invariant (the loop exit condition should not change once the loop starts). There shouldn’t be complicated control-flow or break/continue statements inside the loop. When manipulating arrays in a loop, you should be careful about data dependency. For example, if the loop contains assignments like a[i] += a[i-1], vectorization will not work. ","wordCount":"1282","inLanguage":"en","datePublished":"2021-11-07T00:00:00Z","dateModified":"2021-11-07T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://pradeepniroula.com/expositions/vectorization/"},"publisher":{"@type":"Organization","name":"Bits \u0026 Qubits","logo":{"@type":"ImageObject","url":"https://pradeepniroula.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pradeepniroula.com/ accesskey=h title="Bits & Qubits (Alt + H)">Bits & Qubits</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href="https://scholar.google.com/citations?user=sozxaMYAAAAJ&amp;hl=en" title=Research><span>Research</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://pradeepniroula.com/reviews/ title=Briefs><span>Briefs</span></a></li><li><a href=https://pradeepniroula.com/notes/ title=Notes><span>Notes</span></a></li><li><a href=https://pradeepniroula.com/writings/ title=Writings><span>Writings</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Understanding gcc Vectorization</h1><div class=post-meta><span title='2021-11-07 00:00:00 +0000 UTC'>November 7, 2021</span></div></header><div class=post-content><ul><li><p>It took me a very long time to understand what people mean when they say <code>vectorization</code> (well at least for CPUs).</p></li><li><p>Consider a simple function to multiply an array by a scalar</p></li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#66d9ef>void</span> <span style=color:#a6e22e>vec_mult_scalar</span>(<span style=color:#66d9ef>int</span> a[], <span style=color:#66d9ef>int</span> c) {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>int</span> i;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span><span style=color:#ae81ff>4096</span>; i<span style=color:#f92672>++</span>){
</span></span><span style=display:flex><span>        a[i] <span style=color:#f92672>*=</span> c;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><ul><li>A couple of things to note.</li><li>First, I have assumed the array is of length 4096. This makes digging into the assembly instruction slightly easier.</li><li>Second, the size of the array has to be kind of large. Vectorization doesn&rsquo;t come cheap — for small arrays, the program might actually run faster without any vectorization.</li></ul><hr><h3 id=the-naive-way-of-multiplying-an-array>The Naive Way of Multiplying an Array<a hidden class=anchor aria-hidden=true href=#the-naive-way-of-multiplying-an-array>#</a></h3><ul><li>Let&rsquo;s compile the code above without optimization (by using the compiler flag <code>-O0</code>) and read the assembly output.</li><li><code>gcc -O0 vec_mult_scalar.c -S && cat vec_mult_scalar.S</code></li><li>The assembly output looks like the following</li></ul><pre tabindex=0><code class=language-assembly data-lang=assembly>## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_1:                                 ## =&gt;This Inner Loop Header: Depth=1
	movl	(%rdi,%rax,4), %ecx
	imull	%esi, %ecx
	movl	%ecx, (%rdi,%rax,4)
	incq	%rax
	cmpq	$4096, %rax                     ## imm = 0x1000
	jne	LBB0_1
## %bb.2:
	popq	%rbp
	retq
	.cfi_endproc
                                        ## -- End function
</code></pre><p>Let&rsquo;s try to parse the assembly instruction line by line. The main program only begins from the label <code>LBB0_1</code>. The stuff before is irrelevant to this dicussion. Before we dig into the assembly code above, a couple of things to remember:</p><ul><li>The first thing to know is that, when a function is called, the memory addresses of the arguments passed are stored in registers. The first argument gets stored in regsiter <code>%rdi</code>, the second in <code>%rsi</code> and so on. To learn more about the exact order, I would recommend <a href=https://cs61.seas.harvard.edu/site/2018/Asm2/>this page</a>.</li><li>The register <code>%esi</code> is the lower half of <code>%rsi</code>. While <code>%rsi</code> is a 64-bit register, <code>%esi</code> uses the lower 32-bits. More details <a href=https://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf>here</a> on how the r-registers and e-registers are related.</li><li>The command <code>movl A, B</code> moves stuff from register A to register B. The suffix <code>l</code> simply means that the register has the size <code>long</code>.</li><li>The other tricky thing is the notation <code>(A, B, C)</code>. It usually means: take the stuff in <code>B</code>, multiply that by stuff in <code>C</code> and add it to <code>A</code>. This is usually helpful in fetching array indices. For example, if the first element of an integer array $X$ is stored in the register <code>%rdx</code>, <code>(%rdx, 1, 4)</code> would get the memory address <code>%rdx + 4</code> which would be the array element <code>X[i]</code>, since integer arrays are stored in strides of 4 bytes.</li><li>Similarly, <code>D(A, B, C)</code> means add <code>D</code> to the result of <code>(A, B, C)</code>.</li></ul><p>Now we are ready to understand the assembly output.</p><ul><li><code>movl (%rdi,%rax,4), %ecx</code> simply moves <code>%rdi + 4%rax</code> to <code>%ecx</code>. <code>%rax</code> presumably is holding the loop counter <code>i</code>. You need to multiply by 4 because each memory address stores a byte and an integer is 4 bytes long. This is similar to fetching the array item <code>a[i]</code>.</li><li><code>imull %esi, %ecx</code> multiplies the stuff we just stored in <code>%ecx</code> with whatever is in <code>%esi</code>. The <code>%esi</code> register is just the lower half of <code>%rsi</code>, so it is storing the 32-bit integer we passed as a scalar parameter.</li><li>After the multiplication, we return the multiplied stuff at <code>%ecx</code> back to the array memory <code>movl %ecx, (%rdi,%rax,4)</code>.</li><li><code>incq %rax</code> just increase the counter variable by 1.</li><li><code>cmpq $4096, %rax</code> compares the counter with 4096.</li><li>If the counter is less than 4096, the line <code>jne LBB0_1</code> returns it back to the top of the loop.</li></ul><p>The loop is very dumb. It moves an element of array to a temporary calculator, multiplies the data in calculator, and returns the new data back to the memory where it came from. This process is repeated for each element in the array <strong>one at a time</strong>.</p><hr><h3 id=vectorized-compilation>Vectorized Compilation<a hidden class=anchor aria-hidden=true href=#vectorized-compilation>#</a></h3><p>Now let&rsquo;s turn on vectorization and see what the assembly code looks like in this case. <code>gcc -O3 vectorization.c -S && cat vectorization.s</code> gives the following assembly code.</p><pre tabindex=0><code class=language-assembly data-lang=assembly>## %bb.0:
	pushq	%rbp
	.cfi_def_cfa_offset 16
	.cfi_offset %rbp, -16
	movq	%rsp, %rbp
	.cfi_def_cfa_register %rbp
	movd	%esi, %xmm0
	pshufd	$0, %xmm0, %xmm0                
	xorl	%eax, %eax
	.p2align	4, 0x90
LBB0_1:                                 ## =&gt;This Inner Loop Header: Depth=1
	movdqu	(%rdi,%rax,4), %xmm1
	movdqu	16(%rdi,%rax,4), %xmm2
	movdqu	32(%rdi,%rax,4), %xmm3
	movdqu	48(%rdi,%rax,4), %xmm4
	pmulld	%xmm0, %xmm1
	pmulld	%xmm0, %xmm2
	movdqu	%xmm1, (%rdi,%rax,4)
	movdqu	%xmm2, 16(%rdi,%rax,4)
	pmulld	%xmm0, %xmm3
	pmulld	%xmm0, %xmm4
	movdqu	%xmm3, 32(%rdi,%rax,4)
	movdqu	%xmm4, 48(%rdi,%rax,4)
	addq	$16, %rax
	cmpq	$4096, %rax                     ## imm = 0x1000
	jne	LBB0_1
## %bb.2:
	popq	%rbp
	retq
</code></pre><p>This certainly looks a bit more involved than before. The most important change to note is the presence of registers like <code>%xmm0</code> and new commands like <code>movdqu</code> or <code>pmulld</code>.</p><p>The XMM registers are 128 bit registers. They can hold four 32-bit integers. And it can apply operations parallely across the entire register. What this means for us is that if we can pack the XMM register with four integers, we can multiply all of them at once. I borrowed the following picture from <a href=https://www.intel.com/content/dam/develop/external/us/en/documents/31848-compilerautovectorizationguide.pdf>Intel&rsquo;s Tutorial on Vectorization</a></p><p><img loading=lazy src=/expositions/vectorization-0.png alt></p><p>Let&rsquo;s dig into the assembly code</p><ul><li>Just before the main <code>LBB0_1</code> section begins, we see an instruction <code>movd %esi, %xmm0</code>. It just moves the scalar parameter <code>c</code> to the <code>%xmm0</code> register. A few weird things here. The scalar is really a 32-bit integer. <code>%xmm0</code> is a 128-bit register. And <code>movd</code> is treating the data being moved as a double (64 bit). For now, we can sweep the subtleties under the rug. At this point the register <code>%xmm0</code> looks like the following</li></ul><pre tabindex=0><code>      32           32          32       32 bits 
----------------------------------------------------
             |            |           |     c      
----------------------------------------------------
</code></pre><ul><li>The command that follows immediately <code>pshufd $0, %xmm0, %xmm0</code> is kind of complicated. This <a href=https://www.felixcloutier.com/x86/pshufd>technical reference</a> is also kind of opaque. All we need to know is that after this operation, the <code>%xmm0</code> register looks like the following</li></ul><pre tabindex=0><code>      32           32          32       32 bits 
----------------------------------------------------
        c     |     c      |     c      |     c      
----------------------------------------------------
</code></pre><ul><li>Entering the loop, the sequence of <code>mov</code> statements <code>movdqu (%rdi, %rax,4), %xmm1; movdqu 16(%rdi,%rax,4), %xmm4; ...movdqu 48(%rdi,%rax,4), %xmm4</code> moves blocks of four integers (128 bits) from the array to the XMM register. <code>movdqu</code> just means move double quadwords (just another way of saying 128 bits). The block beginning from <code>(%rdi, %rax,4)</code> gets stored in <code>%xmm1</code>. Since <code>%xmm1</code> has 128 bits, this should fit four integers. The block beginning from <code>16(%rdi, %rax,4)</code> or rather <code>(%rdi, %rax,4) + 16</code> goes to <code>%xmm1</code>. The 16 (with is just the length, in bytes, of four integers) is important because the data between <code>(%rdi, %rax,4) + 0</code> and <code>(%rdi, %rax,4) + 15</code> is stored in <code>%xmm1</code> already.</li><li>The operation <code>pmulld %xmm0, %xmm1</code> just multiplies the block of four integers packed in <code>%xmm1</code> with the scalar value packed in the register <code>%xmm0</code>.</li><li>After the multiplication, the multiplied integers packed in the XMM registers are dragged back to the array memory location.</li><li>For some reason, the compiler uses four XMM registers. It first multiplies two XMM registers in a row, moves the data, and then multiplies the remaining two registers. I do not fully understand why it doesn&rsquo;t multiply all four in a row.</li><li>Finally, once all numbers are multiplied, the loop exits.</li></ul><hr><h3 id=takeaways>Takeaways<a hidden class=anchor aria-hidden=true href=#takeaways>#</a></h3><ul><li>Vectorization is achieved by using these humongous XMM registers that can do parallel operations.</li><li>The compiler can optimize most loops &ndash; as long as the loops are simple enough.</li><li>For auto-vectorization to work, the loop counters must be invariant (the loop exit condition should not change once the loop starts). There shouldn&rsquo;t be complicated control-flow or break/continue statements inside the loop.</li><li>When manipulating arrays in a loop, you should be careful about data dependency. For example, if the loop contains assignments like <code>a[i] += a[i-1]</code>, vectorization will not work.</li></ul></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://pradeepniroula.com/>Bits & Qubits</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>